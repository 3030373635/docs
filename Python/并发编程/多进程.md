---
title: 多进程
---


> 详情参考https://www.cnblogs.com/linhaifeng/articles/7428874.html

# 一、multiprocessing模块

## 1.1 介绍

> python中的多线程无法利用多核优势，如果想要充分地使用多核CPU的资源（os.cpu_count()查看），在python中大部分情况需要使用多进程。Python提供了multiprocessing。
>
> multiprocessing模块用来开启子进程，并在子进程中执行我们定制的任务（比如函数），该模块与多线程模块threading的编程接口类似。
>
> multiprocessing模块的功能众多：支持子进程、通信和共享数据、执行不同形式的同步，提供了Process、Queue、Pipe、Lock等组件。
>
> 需要再次强调的一点是：与线程不同，进程没有任何共享状态，进程修改的数据，改动仅限于该进程内。

## 1.2 使用

> Process([group [, target [, name [, args [, kwargs]]]]])，由该类实例化得到的对象，表示一个子进程中的任务（尚未启动）

**参数**

```python
group参数未使用，值始终为None

target表示调用对象，即子进程要执行的任务

args表示调用对象的位置参数元组，args=(1,2,'egon',)

kwargs表示调用对象的字典,kwargs={'name':'egon','age':18}

name为子进程的名称
```

**方法**

```python
p.start()：启动进程，并调用该子进程中的p.run()

p.run():进程启动时运行的方法，正是它去调用target指定的函数，我们自定义类的类中一定要实现该方法
  
p.terminate():强制终止进程p，不会进行任何清理操作，如果p创建了子进程，该子进程就成了僵尸进程，使用该方法需要特别小心这种情况。如果p还保存了一个锁那么也将不会被释放，进而导致死锁
  
p.is_alive():如果p仍然运行，返回True
  
p.join([timeout]):主线程等待p终止（强调：是主线程处于等的状态，而p是处于运行的状态）。timeout是可选的超时时间，需要强调的是，p.join只能join住start开启的进程，而不能join住run开启的进程
```

**属性**

```python
p.daemon：默认值为False，如果设为True，代表p为后台运行的守护进程，当p的父进程终止时，p也随之终止，并且设定为True后，p不能创建自己的新进程，必须在p.start()之前设置

p.name:进程的名称

p.pid：进程的pid

p.exitcode:进程在运行时为None、如果为–N，表示被信号N结束(了解即可)
  
p.authkey:进程的身份验证键,默认是由os.urandom()随机生成的32字符的字符串。这个键的用途是为涉及网络连接的底层进程间通信提供安全性，这类连接只有在具有相同的身份验证键时才能成功（了解即可）
```

### 1.2.1 开启子进程的两种方式

> 开子进程的目的：让父进程下串行的任务变成并发执行
>
> windows开启子进程：在父进程中创建子进程，会把父进程当做模块导入，所以需要在\_\_name\_\_ == \_\_main\_\_下面操作子进程，不然就会无限创建子进程了
>
> linux不需要在\_\_name\_\_ == \_\_main\_\_下操作子进程

**方式一**

```python
# 方式1
from  multiprocessing import Process
import time
def task(x):
    print("%s is running" % x)
    time.sleep(3)
    print("%s is done" % x)
if __name__ == '__main__':

    p = Process(target=task,args=("子进程",))# Process(target=task,kwargs={"x":"子进程"})
    p.start()
    print("主") # 主进程代码虽然执行完了，但是并没有结束，因为需要做回收操作


```

**方式二**

> 自定义类继承process来创建，**不推荐**

### 1.2.2 进程之间的内存空间是隔离的

```python


from multiprocessing import Process
a = 100
def task():
    global a
    a = 200
    print(a)

if __name__ == '__main__':
    p = Process(target=task)
    p.start()
    p.join() # 父进程原地等待等子进程运行完，才会往下运行
    print(a)
```

### 1.2.3 join用法

> p.join()， 父进程等待子进程的结束才会往下运行，并且会回收子进程（僵尸进程）但是并不会影响其他子进程的运行

```python
from multiprocessing import Process
import time
def task(name,t):
    print("%s in running" % name)
    time.sleep(t)
    print("%s in done" % name)


if __name__ == '__main__':
    start = time.time()
    p1 = Process(target=task,args=("子进程1",1))
    p2 = Process(target=task,args=("子进程2",2))
    p3 = Process(target=task,args=("子进程3",3))

    p1.start()
    p2.start()
    p3.start()



    p1.join() # 父进程原地等待等子进程运行完，才会往下运行，但是并不会影响p2,p3的运行
    p2.join() # 父进程原地等待等子进程运行完，才会往下运行，但是并不会影响p1,p3的运行
    p3.join() # 父进程原地等待等子进程运行完，才会往下运行，但是并不会影响p1,p2的运行

    stop = time.time()

    print("耗时：",stop-start) # 耗时： 3.0130631923675537
```

# 二、僵尸与孤儿进程

```python
参考博客：http://www.cnblogs.com/Anker/p/3271773.html

一：僵尸进程（有害）
　　僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。详解如下

我们知道在unix/linux中，正常情况下子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束，如果子进程一结束就立刻回收其全部资源，那么在父进程内将无法获取子进程的状态信息。

因此，UNⅨ提供了一种机制可以保证父进程可以在任意时刻获取子进程结束时的状态信息：
1、在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等）
2、直到父进程通过wait / waitpid来取时才释放. 但这样就导致了问题，如果进程不调用wait / waitpid的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。

　　任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。  如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。

二：孤儿进程（无害）

　　孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

　　孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。

我们来测试一下（创建完子进程后，主进程所在的这个脚本就退出了，当父进程先于子进程结束时，子进程会被init收养，成为孤儿进程，而非僵尸进程），文件内容

import os
import sys
import time

pid = os.getpid()
ppid = os.getppid()
print 'im father', 'pid', pid, 'ppid', ppid
pid = os.fork()
#执行pid=os.fork()则会生成一个子进程
#返回值pid有两种值：
#    如果返回的pid值为0，表示在子进程当中
#    如果返回的pid值>0，表示在父进程当中
if pid > 0:
    print 'father died..'
    sys.exit(0)

# 保证主线程退出完毕
time.sleep(1)
print 'im child', os.getpid(), os.getppid()

执行文件，输出结果：
im father pid 32515 ppid 32015
father died..
im child 32516 1

看，子进程已经被pid为1的init进程接收了，所以僵尸进程在这种情况下是不存在的，存在只有孤儿进程而已，孤儿进程声明周期结束自然会被init来销毁。


三：僵尸进程危害场景：

　　例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。

四：测试
#1、产生僵尸进程的程序test.py内容如下

#coding:utf-8
from multiprocessing import Process
import time,os

def run():
    print('子',os.getpid())

if __name__ == '__main__':
    p=Process(target=run)
    p.start()
  
    print('主',os.getpid())
    time.sleep(1000)


#2、在unix或linux系统上执行
[root@vm172-31-0-19 ~]# python3  test.py &
[1] 18652
[root@vm172-31-0-19 ~]# 主 18652
子 18653

[root@vm172-31-0-19 ~]# ps aux |grep Z
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root     18653  0.0  0.0      0     0 pts/0    Z    20:02   0:00 [python3] <defunct> #出现僵尸进程
root     18656  0.0  0.0 112648   952 pts/0    S+   20:02   0:00 grep --color=auto Z

[root@vm172-31-0-19 ~]# top #执行top命令发现1zombie
top - 20:03:42 up 31 min,  3 users,  load average: 0.01, 0.06, 0.12
Tasks:  93 total,   2 running,  90 sleeping,   0 stopped,   1 zombie
%Cpu(s):  0.0 us,  0.3 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  1016884 total,    97184 free,    70848 used,   848852 buff/cache
KiB Swap:        0 total,        0 free,        0 used.   782540 avail Mem 

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                                    
root      20   0   29788   1256    988 S  0.3  0.1   0:01.50 elfin                                                                                                                  


#3、
等待父进程正常结束后会调用wait／waitpid去回收僵尸进程
但如果父进程是一个死循环，永远不会结束，那么该僵尸进程就会一直存在，僵尸进程过多，就是有害的
解决方法一：杀死父进程
解决方法二：对开启的子进程应该记得使用join，join会回收僵尸进程
参考python2源码注释
class Process(object):
    def join(self, timeout=None):
        '''
        Wait until child process terminates
        '''
        assert self._parent_pid == os.getpid(), 'can only join a child process'
        assert self._popen is not None, 'can only join a started process'
        res = self._popen.wait(timeout)
        if res is not None:
            _current_process._children.discard(self)

join方法中调用了wait，告诉系统释放僵尸进程。discard为从自己的children中剔除

解决方法三：http://blog.csdn.net/u010571844/article/details/50419798
```

# 三、守护进程

```python
"""
什么是守护进程：
    本质就是子进程，只不过多了一个守护的功能
    守护进程会在主进程"代码执行结束"后就终止，并不守护其他子进程
    注意：守护进程内无法再开启子进程,否则抛出异常：AssertionError: daemonic processes are not allowed to have children
什么时候设置守护进程：
    如果该进程在父进程代码运行完毕后没有存在的意义了，就可以设为守护进程
"""
from multiprocessing import Process
import time
def task(name):
    print("%s is running" % name)
    time.sleep(1)
    print("%s is done" % name)
if __name__ == '__main__':
    p1 = Process(target=task,args=("守护进程",))
    p2 = Process(target=task,args=("子进程1",))

    p1.daemon = True
    p1.start()
    p2.start()

    print("主")
```

# 四、进程的互斥锁

```python
"""
互斥锁：将涉及到修改共享数据的代码变成串行
利用购票举例子：
    查票阶段并发
    购票阶段必须加锁
time.sleep(1)
    让所有过来的进程都能拿到相同的数据，这样方便验证实验

"""


from multiprocessing import Process,Lock
import os
import json
import time
def check():
    with open("test","r",encoding="utf-8") as f:
        dic = json.load(f)
        print("%s查到余票 [%s]" % (os.getpid(),dic["count"]))
def get():
    with open("test","r",encoding="utf-8") as f:
        dic = json.load(f)
        time.sleep(1)
        if dic["count"] >= 1:
            with open("test","w",encoding="utf-8") as f:
                dic["count"] -= 1
                json.dump(dic,f)
                print("%s 购票成功" % os.getpid())
        else:
            print("%s 没有余票" % os.getpid())
def task(mutex):
    check()
    mutex.acquire()
    get()
    mutex.release()
    # with mutex:
    #     get()



if __name__ == '__main__':
    mutex = Lock()
    for i in range(5):
        p = Process(target=task,args=(mutex,))
        p.start()
```

# 五、进程间通信

```python
"""
进程间通信有两种方式
    pipe：管道，由于管道没有实现互斥效果，所以我们使用队列
    queue:pipe + 互斥锁
注意：
    队列基于内存的，使用时应该存放较小的数据
"""
from multiprocessing import Queue
q = Queue(3) # 队列大小为3

# block=True（默认）的意思是入队时队列满了就阻塞住，等待有元素出队在放元素
q.put(1,block=True,timeout=3) 

q.put(2,block=True,timeout=3)
q.put(3,block=True,timeout=3)
print(">>>>")
# block=False的意思是入队时队列满了的话，直接报错，不进行阻塞等待，此时设置timeout没有意义了
q.put(4,block=False) # q.put(1,block=True,timeout=3) == q.get_nowait(1)


# block的用法跟上面是一样的
res1 = q.get()
res2 = q.get()
res3 = q.get()
res4 = q.get(block=False) # q.get(block=False) == q.put_nowait()
```

# 六、生产者消费者模型

## 6.1 low版

```python
"""
什么是生产者消费者模型：
    生产者：程序中产生数据
    消费者：程序中处理数据
    生产者 ->共享的介质（队列）<- 消费者

为何用：
    实现了生产者与消费者的解耦合，生产者和消费者可以不停的生产处理数据，从而提高运行的效率

什么时候用：
    程序中出现一部分程序生产数据，一部分程序处理数据时可考虑使用提高运行效率
"""
from multiprocessing import Process
from multiprocessing import Queue
import time


def producer(q,name,food):
    for i in range(3):
        res = "%s%s" % (food,i)
        time.sleep(0.5)
        q.put(res)
        print("%s 生产了 %s" % (name,res))

def consumer(q,name):
    while True:
        res = q.get()
        if not res:break
        time.sleep(0.5)
        print("%s 消费了 %s" % (name,res))

if __name__ == '__main__':
    q = Queue()
    # 生产者们
    p1 = Process(target=producer,args=(q,"p1","包子"))
    p2 = Process(target=producer,args=(q,"p2","馒头"))
    p3 = Process(target=producer,args=(q,"p3","面饼"))
    # 消费者们
    c1 = Process(target=consumer,args=(q,"c1"))

    p1.start()
    p2.start()
    p3.start()
    c1.start()

    p1.join()
    p2.join()
    p3.join()

    q.put(None)




"""
low版
实现思路：生产者给消费者发结束信号，当生产者都生产完后，主进程往队列丢None，
消费者取到None的话代表队列空了，那么消费者进程就没有存在的意义了
注意：None的个数，取决于消费者的个数，因为生产者生产完就结束了，
但是消费者没有结束，间接导致主进程也没有结束，它的结束是依赖None的
"""
```

## 6.2 终极版

```python
"""
什么是生产者消费者模型：
    生产者：程序中产生数据
    消费者：程序中处理数据
    生产者 ->共享的介质（队列）<- 消费者

为何用：
    实现了生产者与消费者的解耦合，生产者和消费者可以不停的生产处理数据，从而提高运行的效率

什么时候用：
    程序中出现一部分程序生产数据，一部分程序处理数据时可考虑使用提高运行效率
"""
from multiprocessing import Process,JoinableQueue
from multiprocessing import Queue
import time


def producer(q,name,food):
    for i in range(3):
        res = "%s%s" % (food,i)
        time.sleep(0.5)
        q.put(res)
        print("%s 生产了 %s" % (name,res))

def consumer(q,name):
    while True:
        res = q.get()
        time.sleep(0.5)
        print("%s 消费了 %s" % (name,res))
        q.task_done() # 取走一个，队列减1

if __name__ == '__main__':
    q = JoinableQueue()
    # 生产者们
    p1 = Process(target=producer,args=(q,"p1","包子"))
    p2 = Process(target=producer,args=(q,"p2","馒头"))
    p3 = Process(target=producer,args=(q,"p3","面饼"))
    # 消费者们
    c1 = Process(target=consumer,args=(q,"c1"))
    c2 = Process(target=consumer,args=(q,"c2"))
    c1.daemon = True
    c2.daemon = True
    p1.start()
    p2.start()
    p3.start()
    c1.start()
    c2.start()

    p1.join()
    p2.join()
    p3.join()

    q.join() #主进程等待队列为空，才往下运行
"""
终极版
实现思路：消费者给生产者发信号
q.join()运行后，也就是主进程代码运行完毕，此时生产者运行完毕 + 队列为空了，
那么消费者就没有存在的意义了，所以消费者设置成守护进程
"""

```

# 七、进程池

> http://www.lqmblog.com/article/177