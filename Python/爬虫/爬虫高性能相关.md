---
title: 爬虫高性能相关
---


# 一、背景知识

> 爬虫的本质就是一个socket客户端与服务端的通信过程，如果我们有多个url待爬取，只用一个线程且采用串行的方式执行，那只能等待爬取一个结束后才能继续下一个，效率会非常低。
>
> 需要强调的是：对于单线程下串行N个任务，并不完全等同于低效，如果这N个任务都是纯计算的任务，那么该线程对cpu的利用率仍然会很高，之所以单线程下串行多个爬虫任务低效，是因为爬虫任务是明显的IO密集型程序。
>
> 关于IO模型详见[链接：http://www.cnblogs.com/linhaifeng/articles/7454717.html](http://www.cnblogs.com/linhaifeng/articles/7454717.html)
>
> 那么该如何提高爬取性能呢？且看下述概念

# 二、同步/异步/回调机制

## 2.1 同步调用

> 即提交一个任务后就在原地等待任务结束，等到拿到任务的结果后再继续下一行代码

```python
"""
提交一个任务后就在原地等待任务结束，等到拿到任务的结果后再继续下一行代码，这就导致了程序串行执行
"""
import requests

def parse_page(res):
    print('解析 %s' %(len(res)))

def get_page(url):
    print('下载 %s' %url)
    response=requests.get(url)
    if response.status_code == 200:
        return response.text

urls=[
    'https://www.baidu.com/',
    'http://www.sina.com.cn/',
    'https://www.taobao.com'
]
for url in urls:
    res=get_page(url) #调用一个任务，就在原地等待任务结束拿到结果后才继续往后执行
    parse_page(res)
```

## 2.2 简单的解决方案

> 在服务器端使用多线程或者多进程，目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。

```python
"""
有两个缺点：
    - 回调函数与任务耦合了
    - 当需要的并发数非常大时，也就是任务非常多时，再开线程，计算就会承受不了，折中方案，线程池

"""


from threading import Thread
import requests

def parse_page(res):
    print('解析 %s' %(len(res)))

def get_page(url,callback=parse_page):
    print('下载 %s' %url)
    response=requests.get(url)
    if response.status_code == 200:
        callback(response.text)





urls=[
    'https://www.baidu.com/',
    'http://www.sina.com.cn/',
    'https://www.taobao.com'
]
for url in urls:
    t = Thread(target=get_page,args=(url,))
    t.start()

```

**该方案的问题是**

> 开启多进程或都线程的方式，我们是无法无限制地开启多进程或多线程的：在遇到要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而且线程与进程本身也更容易进入假死状态。

## 2.3 改进方案

> 线程池或进程池+回调机制：提交一个任务后并不会等待任务结束，而是继续下一行代码，等有结果，触发回调函数，将结果传给回调函数

> 很多人可能会考虑使用“线程池”或“连接池”。
> “线程池”旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。
> “连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统，如websphere、tomcat和各种数据库等。

```python
"""
线程池的本质和多线程还是一样的，只不过是帮我们管理了多个线程，而且回调函数与任务解耦合了，当
并发数远远大于及其可承受能力时，可以有效保护机器不宕机，但始终没解决大量并发的情况
总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，
"""


from concurrent.futures import ThreadPoolExecutor

import requests

def parse_page(future_obj):
    print('解析 %s' %(len(future_obj.result())))

def get_page(url):
    print('下载 %s' %url)
    response=requests.get(url)
    if response.status_code == 200:
        return response.text



if __name__ == '__main__':


    urls=[
        'https://www.baidu.com/',
        'http://www.sina.com.cn/',
        'https://www.taobao.com'
    ]
    pool = ThreadPoolExecutor(50)
    for url in urls:
        future_obj = pool.submit(get_page,url)
        future_obj.add_done_callback(parse_page) # 绑定回调函数，当任务运行完，激活回调函数，并且把future_obj当参数传给回调函数

```

**改进后的方案其实也存在着问题**

> “线程池”和“连接池”技术也只是在一定程度上缓解了频繁调用IO接口带来的资源占用。而且，所谓“池”始终有其上限，当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有池的时候效果好多少。所以使用“池”必须考虑其面临的响应规模，并根据响应规模调整“池”的大小。
>
> 对应上例中的所面临的可能同时出现的上千甚至上万次的客户端请求，“线程池”或“连接池”或许可以缓解部分压力，但是不能解决所有问题。总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞接口来尝试解决这个问题。

# 三、高性能

> **上述无论哪种解决方案其实没有解决一个性能相关的问题：`IO阻塞`，无论是多进程还是多线程，在遇到IO阻塞时都会被操作系统强行剥夺走CPU的执行权限，程序的执行效率因此就降低了下来。**

> **解决这一问题的关键在于，`我们自己从应用程序级别检测IO阻塞然后切换到我们自己程序的其他任务执行`，这样把我们程序的IO降到最低，我们的程序处于就绪态就会增多，以此来迷惑操作系统，操作系统便以为我们的程序是IO比较少的程序，从而会尽可能多的分配CPU给我们，这样也就达到了提升程序执行效率的目的**

**1. 在python3.3之后新增了asyncio模块，可以帮我们检测IO（只能是网络IO），实现应用程序级别的切换**

**简单使用**

```python
import asyncio

@asyncio.coroutine # 想要哪个任务是异步提交的，就加这个装饰器
def task(task_id,time):
    print("%s is running..." % task_id)
    yield from asyncio.sleep(time) # 但凡涉及到IO的地方加个yield，意思就是遇到IO就保存状态 + 切换
    print("%s is done..." % task_id)

if __name__ == '__main__':

    urls=[
        'https://www.baidu.com/',
        'http://www.sina.com.cn/',
        'https://www.taobao.com'
    ]
    tasks = [
        task("任务1",1),
        task("任务2",2),
        task("任务3",3),
    ]
    loop = asyncio.get_event_loop() # 事件循环
    loop.run_until_complete(asyncio.wait(tasks))
    loop.close()
```

**2. 但asyncio模块只能发tcp级别的请求，不能发http协议，因此，在我们需要发送http请求的时候，需要我们自定义http报头**

```python

import asyncio
import uuid
def parse_page(res):
    with open('%s.html' %uuid.uuid1(),'wb') as f:
        f.write(res)

@asyncio.coroutine # 把set blocking设置成False，一直循环问有没有IO，有IO就切换
def get_page(host,port=80,url='',ssl=False,callback=parse_page):
    #1 建连接
    if ssl:
        port = 443
    print("下载 https:%s:%s/%s" % (host, port, url))
    recv, send = yield from asyncio.open_connection(host=host, port=port,ssl=ssl)
    #2 封装http请求报文
    request_headers = """GET %s HTTP/1.0\r\nHost:%s\r\n
    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36\r\n\r\n
    """ % (url,host)
    request_headers = request_headers.encode('utf-8')
    #3 发送http报文
    send.write(request_headers)
    yield from send.drain()
    #4 接收响应报文中的响应头
    while True:
        line=yield from recv.readline()
        if line == b'\r\n':
            break
        print('%s 响应头: %s' %(host,line))
    #5 接收响应体
    text = yield from recv.read()
    #6 执行回调函数完成解析
    callback(text)
    #7 关闭连接
    send.close()

if __name__ == '__main__':

    tasks=[
        get_page(host='www.baidu.com',url='/s?wd=美女',ssl=True),
        get_page(host='www.cnblogs.com', url='/linhaifeng',ssl=True),

    ]
    loop = asyncio.get_event_loop()
    loop.run_until_complete(asyncio.wait(tasks))
    loop.close()



```

**3. 自定义http报头多少有点麻烦，于是有了aiohttp模块，专门帮我们封装http报头，然后我们还需要用asyncio检测IO实现切换**

```python
import aiohttp
import asyncio

@asyncio.coroutine
def get_page(url):
    print('GET:%s' %url)
    response=yield from aiohttp.request('GET',url)

    data=yield from response.read()

    print(url,data)
    response.close()
    return 1

tasks=[
    get_page('https://www.python.org/doc'),
    get_page('https://www.cnblogs.com/linhaifeng'),
    get_page('https://www.openstack.org')
]

loop=asyncio.get_event_loop()
results=loop.run_until_complete(asyncio.gather(*tasks))
loop.close()

print('=====>',results) #[1, 1, 1]
```

**4. 此外，还可以将requests.get函数传给asyncio，就能够被检测了**

```python
import requests
import asyncio

@asyncio.coroutine
def get_page(func,*args):
    print('GET:%s' %args[0])
    loog=asyncio.get_event_loop()
    furture=loop.run_in_executor(None,func,*args)
    response=yield from furture

    print(response.url,len(response.text))
    return 1

tasks=[
    get_page(requests.get,'https://www.python.org/doc'),
    get_page(requests.get,'https://www.cnblogs.com/linhaifeng'),
    get_page(requests.get,'https://www.openstack.org')
]

loop=asyncio.get_event_loop()
results=loop.run_until_complete(asyncio.gather(*tasks))
loop.close()

print('=====>',results) #[1, 1, 1]
```

**5. gevent + requests**

```python
from gevent import monkey;monkey.patch_all()
import gevent
import requests

def get_page(url):
    print('GET:%s' %url)
    response=requests.get(url)
    print(url,len(response.text))
    return 1

# g1=gevent.spawn(get_page,'https://www.python.org/doc')
# g2=gevent.spawn(get_page,'https://www.cnblogs.com/linhaifeng')
# g3=gevent.spawn(get_page,'https://www.openstack.org')
# gevent.joinall([g1,g2,g3,])
# print(g1.value,g2.value,g3.value) #拿到返回值


#协程池
from gevent.pool import Pool
pool=Pool(2)
g1=pool.spawn(get_page,'https://www.python.org/doc')
g2=pool.spawn(get_page,'https://www.cnblogs.com/linhaifeng')
g3=pool.spawn(get_page,'https://www.openstack.org')
gevent.joinall([g1,g2,g3,])
print(g1.value,g2.value,g3.value) #拿到返回值
```

**6. 封装了gevent+requests模块的grequests模块**

```python
#pip3 install grequests

import grequests

request_list=[
    grequests.get('https://wwww.xxxx.org/doc1'),
    grequests.get('https://www.cnblogs.com/linhaifeng'),
    grequests.get('https://www.openstack.org')
]


##### 执行并获取响应列表 #####
# response_list = grequests.map(request_list)
# print(response_list)

##### 执行并获取响应列表（处理异常） #####
def exception_handler(request, exception):
    # print(request,exception)
    print("%s Request failed" %request.url)

response_list = grequests.map(request_list, exception_handler=exception_handler)
print(response_list)
```

**7、twisted：是一个网络框架，其中一个功能是发送异步请求，检测IO并自动切换**

```python
'''
#问题一：error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": http://landinghub.visualstudio.com/visual-cpp-build-tools
https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted
pip3 install C:\Users\Administrator\Downloads\Twisted-17.9.0-cp36-cp36m-win_amd64.whl
pip3 install twisted

#问题二：ModuleNotFoundError: No module named 'win32api'
https://sourceforge.net/projects/pywin32/files/pywin32/

#问题三：openssl
pip3 install pyopenssl
'''

#twisted基本用法
from twisted.web.client import getPage,defer
from twisted.internet import reactor

def parse_page(res):
    return len(res)
def all_done(res):
    print(res)
    reactor.stop()
urls = [
    'https://www.baidu.com',
    'https://www.taobao.com',
    'https://www.openstack.org'
]
tasks = []
for url in urls:
    obj = getPage(url.encode("utf-8")) # 并不会马上执行
    tasks.append(obj)
    obj.addCallback(parse_page)



#twisted的getPage的详细用法
from twisted.internet import reactor
from twisted.web.client import getPage
import urllib.parse


def one_done(arg):
    print(arg)
    reactor.stop()

post_data = urllib.parse.urlencode({'check_data': 'adf'})
post_data = bytes(post_data, encoding='utf8')
headers = {b'Content-Type': b'application/x-www-form-urlencoded'}
response = getPage(bytes('http://dig.chouti.com/login', encoding='utf8'),
                   method=bytes('POST', encoding='utf8'),
                   postdata=post_data,
                   cookies={},
                   headers=headers)
response.addBoth(one_done)

reactor.run()
```

**8、tornado**

```python
from tornado.httpclient import AsyncHTTPClient
from tornado.httpclient import HTTPRequest
from tornado import ioloop


def handle_response(response):
    """
    处理返回值内容（需要维护计数器，来停止IO循环），调用 ioloop.IOLoop.current().stop()
    :param response:
    :return:
    """
    if response.error:
        print("Error:", response.error)
    else:
        print(response.body)


def func():
    url_list = [
        'http://www.baidu.com',
        'http://www.bing.com',
    ]
    for url in url_list:
        print(url)
        http_client = AsyncHTTPClient()
        http_client.fetch(HTTPRequest(url), handle_response)


ioloop.IOLoop.current().add_callback(func)
ioloop.IOLoop.current().start()




#发现上例在所有任务都完毕后也不能正常结束，为了解决该问题，让我们来加上计数器
from tornado.httpclient import AsyncHTTPClient
from tornado.httpclient import HTTPRequest
from tornado import ioloop

count=0

def handle_response(response):
    """
    处理返回值内容（需要维护计数器，来停止IO循环），调用 ioloop.IOLoop.current().stop()
    :param response:
    :return:
    """
    if response.error:
        print("Error:", response.error)
    else:
        print(len(response.body))

    global count
    count-=1 #完成一次回调，计数减1
    if count == 0:
        ioloop.IOLoop.current().stop() 

def func():
    url_list = [
        'http://www.baidu.com',
        'http://www.bing.com',
    ]

    global count
    for url in url_list:
        print(url)
        http_client = AsyncHTTPClient()
        http_client.fetch(HTTPRequest(url), handle_response)
        count+=1 #计数加1

ioloop.IOLoop.current().add_callback(func)
ioloop.IOLoop.current().start()
```

**9、番外：自定义异步IO**

> 如果其他人调用该框架从调用的方式来看是异步IO，但是内部却不是

**知识储备**

```
爬虫性能相关

    - 傻等
        response = requests.get(....)
    - 机智
        response = requests.get(....)
        response = requests.get(....)
        response = requests.get(....)
        response = requests.get(....)

    角色：使用者
        - 多线程
        - 多线程
        - 协程（微线程） + 异步IO =》 1个线程发送N个Http请求
            - asyncio
                - 示例1：asyncio.sleep(5)
                - 示例2：自己封装Http数据包
                - 示例3：asyncio+aiohttp
                    aiohttp模块：封装Http数据包 pip3 install aiohttp
                - 示例4：asyncio+requests
                    requests模块：封装Http数据包 pip3 install requests
            - gevent，greenlet+异步IO
                    pip3 install greenlet
                    pip3 install gevent
                - 示例1：gevent+requests
                - 示例2：gevent（协程池，最多发多少个请求）+requests
                - 示例3：gevent+requests => grequests
                        pip3 install grequests

            - Twisted
                pip3 install twisted
            - Tornado
                pip3 install tornado

            =====> gevent > Twisted > Tornado > asyncio


    角色：NB开发者
        自己写一个基于事件循环(驱动)的异步非阻塞模块
        事件循环：循环监视事件，看有没有返回结果，有结果处理结果
        知识储备：
            1. socket客户端、服务端
                连接阻塞
                setblocking(0): 无数据（连接无响应；数据未返回）就报错

            2. IO多路复用
                客户端：
                try:
                    socket对象1.connet()
                    socket对象2.connet()
                    socket对象3.connet()
                except Ex..
                    pass

                while True:
                    r,w,e = select.select([socket对象1,socket对象2,socket对象3,],[socket对象1,socket对象2,socket对象3,],[],0.05)
                    r = [socket对象1,] # 表示有人给我发送数据
                        xx = socket对象1.recv()
                    w = [socket对象1,] # 表示我已经和别人创建连接成功:
                        socket对象1.send('"""GET /index HTTP/1.0\r\nHost: baidu.com\r\n\r\n"""')


            3.
                class Foo:

                    def fileno(self):
                        obj = socket()
                        return obj.fileno()

                r,w,e = select.select([socket对象？,对象？,对象？,Foo()],[],[])
                # 监听的对象不一定是socket对象，只要对象有fileno方法，并返回一个文件描述符就行了
                - select内部：对象.fileno()
                - Foo()内部封装socket文件描述符
```

**代码**

```python
import socket
import select
"""
# HTTP请求，阻塞
# 1.建立三次握手
client = socket.socket()
client.connect(('www.baidu.com',80))
print("双向管道建立成功...")
# 2.发送HTTP头
client.send("bGET / HTTP/1.0\r\nHost:www.baidu.com\r\n\r\n")
# 3.等待服务器响应
data = client.recv(8096)
print(data)
# 4.关闭连接
client.close()

"""
"""
# 1.建立三次握手
client = socket.socket()
client.setblocking(False)
try:
    client.connect(('www.baidu.com',80))
    print("双向管道建立成功...")
except BlockingIOError as e:
    print(e)

# 2.发送HTTP头
client.send(b"GET / HTTP/1.0\r\nHost:www.baidu.com\r\n\r\n")
# 3.等待服务器响应
data = client.recv(8096)
print(data)
# 4.关闭连接
client.close()

"""
class HttpResponse():
    def __init__(self,data):
        self.data = data
        self.headers = {}
        self.body = {}
        self.initialize()
    def initialize(self):
        headers,body = self.data.split(b'\r\n\r\n')
        self.body = body
        headers_list = headers.split(b"\r\n")
        for header in headers_list[1:]:
            header_name,header_value = header.split(b":")[0],header.split(b":")[1]
            self.headers[header_name] = header_value

class HttpRequest():
    def __init__(self,sk,host,callback):
        self.socket = sk
        self.host = host
        self.callback = callback
    def fileno(self):
        return self.socket.fileno()
class AsyncRequest:
    def __init__(self):
        self.conn = []
        self.connection = [] # 用于检测是否连接成功
    def add_request(self,host,port=80,callback=None):
        try:
            sk = socket.socket()
            sk.setblocking(False) # 设置成非阻塞
            sk.connect((host,port))
        except BlockingIOError as e:
            pass
        request = HttpRequest(sk,host,callback)
        self.conn.append(request)
        self.connection.append(request)
    def run(self): # 事件循环
        while True:
            rl,wl,el = select.select(self.conn,self.connection,[],5)
            for w in wl:
                # 只要能循环到，表示socket和服务器连接成功
                temp = "GET / HTTP/1.1\r\nHost:%s\r\n\r\n" % w.host
                w.socket.send(temp.encode("utf-8"))
                self.connection.remove(w)
            for r in rl:
                data = b''
                while True:
                    try:
                        temp = r.socket.recv(1024)
                        data += temp
                    except Exception as e:
                        break
                response = HttpResponse(data)
                r.callback(response) # 执行回调函数
                r.socket.close()
                self.conn.remove(r)
            if len(self.conn) == 0:
                break
def f1(response):
    print(response.headers)
def f2(response):
    print(response.headers)
def f3(response):
    print(response.headers)

url_list = [
    {'host':'www.baidu.com','callback':f1},
    {'host':'www.bing.com','callback':f2},
    {'host':'www.zhihu.com','callback':f3}
]
request = AsyncRequest()
for item in url_list:
    request.add_request(item['host'],callback=item['callback'])

request.run()